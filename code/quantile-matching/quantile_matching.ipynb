{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ac9d14-5026-4d99-8b54-6d2a1ce42dc7",
   "metadata": {},
   "source": [
    "# Quantile Matching and LightGBM\n",
    "\n",
    "This notebook showcases the use of quantile matching paired with LightGBM quantile regression to predict probability distributions.\n",
    "\n",
    "To install the needed dependencies, follow the instructions in the README at the root of the repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886bc51-dad6-45f2-a855-95ad1d8c3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy import optimize, stats\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from sklearn.datasets import load_diabetes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2777f70-6069-4ab0-8653-bc6d00bec144",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdae5a2-fc71-44c9-97fc-d8d0f53d72d8",
   "metadata": {},
   "source": [
    "The goal of quantile matching is to estimate a distribution function given a sample of quantile values.\n",
    "\n",
    "The curve doesn't have to perfectly fit the quantiles, but rather be as close as possible, while keeping the properties that make it a distribution function.\n",
    "Specifically, we are interested in estimating the inverse cumulative distribution function: given a probability `alpha`, we want to know what is the value `v` for which `P(X<v)=alpha`, where `P` represent a probability and `X` the random variable. This can be used to represent uncertainty and estimate prediction intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6b7ff-71be-4f2d-8272-0af523976799",
   "metadata": {},
   "source": [
    "Let's define 3 alternatives to estimate such function from a set of quantiles:\n",
    "- Fit a Normal Distribution\n",
    "- Fit a Half Normal Distributio\n",
    "- Cubic Interpolation: use cubic splines to estimate a smooth increasing curve.\n",
    "\n",
    "To do that, we use an easy-to-extend design pattern: \n",
    "- a base abstract class which defines an interface\n",
    "- a set of concrete classes which implement the different methods\n",
    "- a factory that returns the class for the desired method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22d1c6-a623-41f7-80a6-90b83b994476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileMatcherBase(ABC):\n",
    "    @abstractmethod\n",
    "    def fit_one(self, alphas, quant_values):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_one(self, alphas):\n",
    "        pass\n",
    "\n",
    "\n",
    "def quantile_matcher_factory(match, **kwargs) -> QuantileMatcherBase:\n",
    "    matcher_map = {\n",
    "        \"normal\": QuantileMatcherNormCurvFit,\n",
    "        \"half_normal\": QuantileMatcherHalfNormCurvFit,\n",
    "        \"cubic_interpolation\": QuantileMatcherCubicInterpolation,\n",
    "    }\n",
    "    if match not in matcher_map:\n",
    "        raise ValueError(f\"Unknown matcher {match}\")\n",
    "\n",
    "    return matcher_map[match](**kwargs)\n",
    "\n",
    "\n",
    "class QuantileMatcherNormCurvFit(QuantileMatcherBase):\n",
    "    \"\"\"Normal distribution quantile matcher.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.params = None\n",
    "\n",
    "    def fit_one(self, alphas, quant_values):\n",
    "        self.params, _ = optimize.curve_fit(\n",
    "            lambda x, mu, sigma: stats.norm.isf(x, mu, sigma),\n",
    "            alphas,\n",
    "            1 - quant_values,\n",
    "        )\n",
    "\n",
    "    def predict_one(self, alphas):\n",
    "        return 1 - stats.norm.isf(alphas, *self.params)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class QuantileMatcherHalfNormCurvFit(QuantileMatcherBase):\n",
    "    \"\"\"Half-Normal distribution quantile matchers.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.below = QuantileMatcherNormCurvFit()\n",
    "        self.above = QuantileMatcherNormCurvFit()\n",
    "\n",
    "    def fit_one(self, alphas, quant_values):\n",
    "        self.below.fit_one(alphas[alphas<=0.5],quant_values[alphas<=0.5])\n",
    "        self.above.fit_one(alphas[alphas>=0.5],quant_values[alphas>=0.5])\n",
    "        \n",
    "        mu = (self.below.params[0] + self.above.params[0]) / 2\n",
    "        self.below.params[0] = mu\n",
    "        self.above.params[0] = mu\n",
    "\n",
    "    def predict_one(self, alphas):\n",
    "        pred = self.above.predict_one(alphas)\n",
    "        pred_below = self.below.predict_one(alphas)\n",
    "        pred[alphas<0.5] = pred_below[alphas<0.5]\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "\n",
    "class QuantileMatcherCubicInterpolation(QuantileMatcherBase):\n",
    "    \"\"\"Increasing cubic interpolation quantile matcher.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.params = None\n",
    "\n",
    "    def fit_one(self, alphas, quant_values):\n",
    "        self.interp = PchipInterpolator(alphas, quant_values)\n",
    "\n",
    "    def predict_one(self, alphas):\n",
    "        return self.interp(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb873c-1987-4e96-b7f8-e4f005304f05",
   "metadata": {},
   "source": [
    "Now, let's define a class that estimates a set of quantiles, and uses the methods above to predict them on a fine grid.\n",
    "\n",
    "For this, we are going to use LightGBM quantile regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7aba7b-a0b9-4b85-9ecd-94b1774813d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProbLGBMRegressor:\n",
    "    _forbidden_keys = (\n",
    "        \"objective\",\n",
    "        \"objective_type\",\n",
    "        \"app\",\n",
    "        \"application\",\n",
    "        \"loss\",\n",
    "        \"alpha\",\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        alphas=np.array([0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]), \n",
    "        **lgbm_args\n",
    "    ):\n",
    "        self.alphas = alphas\n",
    "\n",
    "        for key in self._forbidden_keys:\n",
    "            if key in lgbm_args:\n",
    "                raise ValueError(f\"{key} parameter is not allowed.\")\n",
    "\n",
    "        self._models = {}\n",
    "        for alpha in self.alphas:\n",
    "            self._models[alpha] = LGBMRegressor(\n",
    "                objective=\"quantile\", alpha=alpha, **lgbm_args\n",
    "            )\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        for alpha in self.alphas:\n",
    "            self._models[alpha].fit(x, y)\n",
    "\n",
    "    def predict_raw(self, x):\n",
    "        return pd.DataFrame(\n",
    "            {alpha: model.predict(x) for alpha, model in self._models.items()}\n",
    "        )\n",
    "\n",
    "    def predict_cdf(\n",
    "        self,\n",
    "        x,\n",
    "        inference_alphas=np.linspace(0.001, 0.999, 999),\n",
    "        match=\"normal_curve_fit\",\n",
    "        **matcher_params,\n",
    "    ):\n",
    "        # Compute predictions for the limited set of quantiles.\n",
    "        raw_preds = self.predict_raw(x)\n",
    "\n",
    "        # Estimate.\n",
    "        matcher = quantile_matcher_factory(match, **matcher_params)\n",
    "        predictions = []\n",
    "        for _, row in raw_preds.iterrows():\n",
    "            matcher.fit_one(self.alphas, row.values)\n",
    "            preds = matcher.predict_one(inference_alphas)\n",
    "            predictions.append(preds)\n",
    "\n",
    "        return pd.DataFrame(predictions, columns=inference_alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e590e92-a288-48d1-b85d-bc0b58026057",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "To showcase quantile matching, let's use the diabetes dataset: 10 features are used to predict a target that quantifies the development of diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd79b92-b949-44f2-8c20-ab9ee9efcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_diabetes(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7234f-dbf9-4d89-aaa9-bc68b27ae5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c17de-dd7a-47e2-8638-08dbc14aaa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a regressor\n",
    "prob_lgbm = ProbLGBMRegressor()\n",
    "prob_lgbm.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b6051-050a-4c72-90d1-de3180ebe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Predict the distributions with all methods\n",
    "predicted_cdf = {}\n",
    "for match in [\"normal\",\"half_normal\",\"cubic_interpolation\"]:\n",
    "    predicted_cdf[match] = prob_lgbm.predict_cdf(x, match=match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee029125-cec9-4e44-b916-f2b819b5797b",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137a7832-6dab-43ec-be19-367879d3b5dd",
   "metadata": {},
   "source": [
    "Let's visualize these distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53588ab5-0352-4c9b-ac04-deb5f1898a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization purposes, we predict also the \"raw\" values\n",
    "predicted_raw = prob_lgbm.predict_raw(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b699582-04b1-4c12-8738-091968d2de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fig_cumulative_distribution_function(predicted_cdf, predicted_raw, idx):\n",
    "    # Small artifact to ensure same range in figures\n",
    "    max_limit = max([pred.iloc[idx, -1] for pred in predicted_cdf.values()]) + 5\n",
    "    min_limit = max([pred.iloc[idx, 0] for pred in predicted_cdf.values()]) - 5\n",
    "\n",
    "    # Create traces for each distribution.\n",
    "    trace = []\n",
    "    for match, pred_cdf in predicted_cdf.items():\n",
    "        x = [min_limit] + list(pred_cdf.iloc[idx].values) + [max_limit]\n",
    "        y = [0] + list(pred_cdf.columns) + [1]\n",
    "        trace.append(go.Scatter(x=x, y=y, mode=\"lines\", name=match.title()))\n",
    "\n",
    "    # Add trace for raw quantile predictions.\n",
    "    trace.append(\n",
    "        go.Scatter(\n",
    "            x=predicted_raw.iloc[idx],\n",
    "            y=predicted_raw.columns,\n",
    "            mode=\"markers\",\n",
    "            name=\"Raw Predictions\",\n",
    "            marker={\"size\": 10},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure(trace)\n",
    "    fig.update_layout(\n",
    "        title=\"Cumulative Distribution Functions\",\n",
    "        yaxis_title=\"alpha\",\n",
    "        xaxis_title=\"quantile\",\n",
    "    )\n",
    "    # Set x-axis limits\n",
    "    fig.update_xaxes(range=(min_limit, max_limit))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_fig_probability_distribution_function(predicted_cdf, idx):\n",
    "    trace = []\n",
    "\n",
    "    for match, pred_cdf in predicted_cdf.items():\n",
    "        quantiles = pred_cdf.iloc[idx].values\n",
    "        icdf_values = pred_cdf.columns.values\n",
    "\n",
    "        # Estimate the PDF using finite differences\n",
    "        diff_icdf = np.diff(icdf_values)\n",
    "        diff_quantiles = np.diff(quantiles)\n",
    "        pdf_est = diff_icdf / diff_quantiles\n",
    "\n",
    "        # Create a Plotly figure for the estimated PDF\n",
    "        trace.append(\n",
    "            go.Scatter(\n",
    "                x=quantiles[:-1],\n",
    "                y=pdf_est,\n",
    "                mode=\"lines\",\n",
    "                fill=\"tozeroy\",\n",
    "                name=match,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=trace)\n",
    "\n",
    "    # Add labels and title\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"quantile\",\n",
    "        yaxis_title=\"probability density\",\n",
    "        title=\"Estimated Probability Density Function\",\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1bd0f-6153-4f95-99f0-0a28c0204a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the cumulative and probability distribution for the first few predictions.\n",
    "for idx in range(5):\n",
    "    get_fig_cumulative_distribution_function(predicted_cdf, predicted_raw, idx).show()\n",
    "    get_fig_probability_distribution_function(predicted_cdf, idx).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2b772-4d75-4bc2-91ba-2b16fcd8cf65",
   "metadata": {},
   "source": [
    "We can see that the normal and the half-normal distribution don't coincide, suggesting an asymmetry in the true underlying distribution. \n",
    "\n",
    "We also notice that the cubic interpolation often gives multi-modal extreme results. This is due to the fact that interpolation is not constrained and tends to have high derivative when fitting close points. These results are probably not realistic, and a smoothing technique might help in this setting.\n",
    "\n",
    "All in all, the half-normal distribution might be the best choice, as it provides a realistic distribution while being able to model asymmetric behaviours. \n",
    "However, the best way to choose the matchin algorithm would be to cross-validate predictions and compute some relevant metrics, such as width of the prediction intervals combined with their accuracy (a 90% interval should contain the prediction 90% of the time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc23d9-4dbb-406b-a602-9c02eb4783e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effective-forecasting",
   "language": "python",
   "name": "effective-forecasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
