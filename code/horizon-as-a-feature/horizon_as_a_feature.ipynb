{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c91233c-870f-4461-8362-fcd3d112b927",
   "metadata": {},
   "source": [
    "# Horizon as a Feature\n",
    "\n",
    "In this notebook we illustrate how to train a single model for multiple horizons by the use of an additional horizon feature. \n",
    "\n",
    "We compare this approach with the traditional one, i.e. one model for horizon.\n",
    "\n",
    "As an example, we use precipitation data from a city in Switzerland (Lugano)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331971d0-14c5-435b-b695-b981cb3fe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caae1a2-3b7c-4278-b5c7-ba9c55a93baa",
   "metadata": {},
   "source": [
    "## Load Climate data\n",
    "\n",
    "\n",
    "The data can be found [here](https://www.meteoswiss.admin.ch/services-and-publications/applications/ext/climate-tables-homogenized.html).\n",
    "\n",
    "\n",
    "First, let's load the climate data in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b6622-9945-46b2-a783-bdc9b6c20d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_climate_data(path):\n",
    "    # Load data in a dataframe.\n",
    "    with open(path,\"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        data = f.readlines()\n",
    "    columns = data[27].split()\n",
    "    data = [v.split() for v in data[28:]]\n",
    "    data = pd.DataFrame(data, columns = columns)\n",
    "    \n",
    "    # Fix time\n",
    "    data[\"time\"] = pd.to_datetime(data.Year + \"-\" + data.Month.astype(str))\n",
    "    data = data.drop(columns = [\"Year\",\"Month\"])\n",
    "    data = data.set_index(\"time\")\n",
    "    \n",
    "    # Fix types\n",
    "    data = data.replace(\"NA\",None)\n",
    "    return data.astype(float)\n",
    "\n",
    "\n",
    "DATA_PATH = \"./data/climate-reports-tables-homogenized_LUG.txt\"\n",
    "data = load_climate_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432fcda-0dab-4a0d-96c7-6b2c3c691fd6",
   "metadata": {},
   "source": [
    "## Quick Exploration\n",
    "\n",
    "Let's have a quick look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7246d5-2298-486d-884a-cf3910690bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a8f45-f6aa-4924-bfbe-2b4ff0e3ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb7690-46b4-4802-a65b-785bde62827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the data.\n",
    "def show_data(data,title=\"\"):\n",
    "    trace = [go.Scatter(x=data.index,y=data[c],name=c) for c in data.columns]\n",
    "    go.Figure(trace,layout=dict(title=title)).show()\n",
    "\n",
    "show_data(data,\"Weather Data in Lugano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24af57-1f3c-4285-ac87-b61eb79d0dcc",
   "metadata": {},
   "source": [
    "We have 150+ years of monthly temperatures and precipitations in the region of Lugano (Switzerland). \n",
    "\n",
    "We see that the data is seasonal and that precipitation is more irregular than temperature, as expected. \n",
    "\n",
    "Since precipitation it's harder to predict, it's also more interesting! Let's try to forecast its values for the next 1, 2, and 3 months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b14c9c-0ecc-4557-bec7-12207aa6df8f",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "\n",
    "Let's prepare the data to train a forecasting model. We are gonna use lagged values of precipitation and temperature to forecast future values of precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae16318-f7d4-426f-b3a6-695ff531522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_features(data, horizon):\n",
    "    targ = build_target(data.Precipitation, horizon)\n",
    "    feat = build_features(data, horizon)\n",
    "    \n",
    "    # Drop missing values generated by lags/horizon.\n",
    "    idx = ~(feat.isnull().any(axis=1) | targ.isnull())\n",
    "    feat = feat.loc[idx]\n",
    "    targ = targ.loc[idx]\n",
    "    \n",
    "    return targ, feat\n",
    "\n",
    "\n",
    "def build_target(series, horizon):\n",
    "    return series.shift(-horizon)\n",
    "\n",
    "\n",
    "def build_features(data, horizon):\n",
    "    \"\"\"Build lagged features.\n",
    "    \n",
    "    We depend on horizon due to relative lags shift. \n",
    "    E.g, if the horizon is equal to 1, the target value of 12 months \n",
    "    before corresponds to a lag of 11.\n",
    "    \"\"\"\n",
    "    # Here we hardcode values to simplify code reading, but everything could \n",
    "    # (and should) be parametrized.\n",
    "    precipitation_lags = [0, 1, 2, 12 - horizon, 24 - horizon, 36 - horizon]\n",
    "    temperature_lags = [0, 1, 12 - horizon, 24 - horizon]\n",
    "    \n",
    "    # Concatenate precipitation and temperature features.\n",
    "    features = pd.concat(\n",
    "        [\n",
    "            build_lagged_features(data.Precipitation, lags=precipitation_lags),\n",
    "            build_lagged_features(data.Temperature, lags=temperature_lags),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    # Add horizon_month as a feature.\n",
    "    features[\"horizon_month\"] = (features.index.month + horizon - 1) % 12 + 1\n",
    "\n",
    "    # Trick to later allow concatenation of features for different target horizons.\n",
    "    features = features.rename(\n",
    "        columns={\n",
    "            f\"Precipitation_lag_{12-horizon}\": \"Precipitation_lag_12_before_target\",\n",
    "            f\"Precipitation_lag_{24-horizon}\": \"Precipitation_lag_24_before_target\",\n",
    "            f\"Precipitation_lag_{36-horizon}\": \"Precipitation_lag_36_before_target\",\n",
    "            f\"Temperature_lag_{12-horizon}\": \"Temperature_lag_12_before_target\",\n",
    "            f\"Temperature_lag_{24-horizon}\": \"Temperature_lag_24_before_target\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def build_lagged_features(series, lags):\n",
    "    return pd.concat([series.shift(lag).rename(f\"{series.name}_lag_{lag}\") for lag in lags] ,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c1e6d-40b1-45c6-a8b5-41a62c44ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build the targets and features for each horizon.\n",
    "HORIZONS = [1,2,3]\n",
    "target_features = {h: build_target_features(data, h) for h in HORIZONS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746a637-e59c-4098-9fee-18dd7f9dc6f0",
   "metadata": {},
   "source": [
    "## Split Train & Test\n",
    "\n",
    "Let's consider the last 10 years as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9c6fe-5f91-4270-a55c-9211e2f96f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10 * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65495dbf-0f31-4efb-a795-ef60cfc49eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(target_features, test_size):\n",
    "    targ_feat_split = {}\n",
    "    for horizon, (targ,feat) in target_features.items():\n",
    "        targ_train = targ.iloc[:-test_size]\n",
    "        feat_train = feat.iloc[:-test_size]\n",
    "        targ_test = targ.iloc[-test_size:]\n",
    "        feat_test = feat.iloc[-test_size:]\n",
    "        \n",
    "        targ_feat_split[horizon] = targ_train, feat_train, targ_test, feat_test\n",
    "        \n",
    "    return targ_feat_split\n",
    "\n",
    "\n",
    "targ_feat_split = split_train_test(target_features, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bc4fb-866d-4939-a595-3e857ebc195c",
   "metadata": {},
   "source": [
    "## Models training\n",
    "\n",
    "We are going to use LightGBM as ML model. \n",
    "Since we only care about comparing the two different approaches, we'll keep default hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934362d6-a597-4c02-8580-1f07658a0849",
   "metadata": {},
   "source": [
    "### Train: One different model per horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36bcab-3976-4d45-b72d-24662ded7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_by_horizon(targ_feat_split, model_params=None):\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "    \n",
    "    # Train one model for each horizon\n",
    "    models_by_horizon = {}\n",
    "    for horizon, (targ_train,feat_train,_,_) in targ_feat_split.items():\n",
    "        model = LGBMRegressor(**model_params)\n",
    "        model.fit(feat_train, targ_train)\n",
    "        models_by_horizon[horizon] = model\n",
    "        \n",
    "    return models_by_horizon\n",
    "\n",
    "\n",
    "models_by_horizon = train_models_by_horizon(targ_feat_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5876f25-37ef-4146-896a-51b425a9aeb9",
   "metadata": {},
   "source": [
    "### Train: One model for all horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f1e62-6487-4782-af21-0db80b0e1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_across_horizons(targ_feat_split, model_params=None):\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "    \n",
    "    # Concatenate data across horizons.\n",
    "    targ_train_all = []\n",
    "    feat_train_all = []\n",
    "    for horizon, (targ_train,feat_train,_,_) in targ_feat_split.items():\n",
    "        # Add horizon as a feature.\n",
    "        feat_train = feat_train.copy()\n",
    "        feat_train[\"target_horizon\"] = horizon\n",
    "        \n",
    "        targ_train_all.append(targ_train)\n",
    "        feat_train_all.append(feat_train)\n",
    "        \n",
    "    targ_train_all = pd.concat(targ_train_all)\n",
    "    feat_train_all = pd.concat(feat_train_all)\n",
    "    \n",
    "    # Train a single model.\n",
    "    model = LGBMRegressor(**model_params)\n",
    "    model.fit(feat_train_all, targ_train_all)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_shared = train_model_across_horizons(targ_feat_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63be8e4-cb8b-4e59-af36-b1cb431276fc",
   "metadata": {},
   "source": [
    "## Predict on the Test set\n",
    "\n",
    "Let's make predictions on the test set with the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4217c37-30b1-489d-8cfa-e8ceafa49c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_models_by_horizon(targ_feat_split, models_by_horizon):\n",
    "    preds = {}\n",
    "    for horizon, (_,_,_,feat_test) in targ_feat_split.items():\n",
    "        preds[horizon] = models_by_horizon[horizon].predict(feat_test)\n",
    "    return preds\n",
    "\n",
    "\n",
    "preds_by_horizon = predict_models_by_horizon(targ_feat_split, models_by_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b9529-e300-47dd-a688-b01c1e63980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_across_horizons(targ_feat_split, model):\n",
    "    preds = {}\n",
    "    for horizon, (_,_,_,feat_test) in targ_feat_split.items():\n",
    "        # Add horizon as a feature.\n",
    "        feat_test = feat_test.copy()\n",
    "        feat_test[\"target_horizon\"] = horizon\n",
    "        \n",
    "        preds[horizon] = model.predict(feat_test)\n",
    "    return preds\n",
    "\n",
    "\n",
    "preds_model_shared = predict_model_across_horizons(targ_feat_split, model_shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5f4f2-35a6-4fd1-a895-c1bf07d4f2a7",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b869711-8d4f-48a2-a90f-c68d670c6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the output in a convenient format.\n",
    "output = {}\n",
    "for horizon in HORIZONS:\n",
    "    df = targ_feat_split[horizon][2].rename(\"target\").to_frame()\n",
    "    df[\"pred_model_by_horizon\"] = preds_by_horizon[horizon]\n",
    "    df[\"pred_model_shared\"] = preds_model_shared[horizon]\n",
    "    output[horizon] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb5551c-6de4-4af7-96ed-1ff083885029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(output):\n",
    "    output_all = pd.concat(output.values())\n",
    "    mae_by_horizon = (output_all.target - output_all.pred_model_by_horizon).abs().mean()\n",
    "    mae_shared = (output_all.target - output_all.pred_model_shared).abs().mean()\n",
    "\n",
    "    print(\"                 BY HORIZON     SHARED\")\n",
    "    print(f\"MAE overall    :    {mae_by_horizon:.1f}         {mae_shared:.1f}\\n\")\n",
    "    for h,df in output.items():   \n",
    "        mae_by_horizon = (df.target - df.pred_model_by_horizon).abs().mean()\n",
    "        mae_shared = (df.target - df.pred_model_shared).abs().mean()\n",
    "        print(f\"MAE - horizon {h}:    {mae_by_horizon:.1f}         {mae_shared:.1f}\")\n",
    "\n",
    "# Let's show some statistics.\n",
    "print_stats(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a6f64a-ef4a-4672-b0ae-c998397f4864",
   "metadata": {},
   "source": [
    "We see that the shared model across horizons always leads to lower MAE.\n",
    "\n",
    "This is somewhat expected, as it was trained on a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8385b-364d-4b68-be0e-9b176859eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the predictions.\n",
    "for horizon, df in output.items():\n",
    "    show_data(df,f\"Predictions at Horizon {horizon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384539c-c42a-4af1-9192-a0f7901d145e",
   "metadata": {},
   "source": [
    "We see that the models still fail to capture extreme events (like August 2014). \n",
    "\n",
    "This is normal since:\n",
    "- we have very limited information on the real state of the system\n",
    "- extreme events are very hard to predict with ML, since we have limited observations in the training set by definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9a4d4-f0f5-4684-82e9-80c8ba235376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effective-forecasting",
   "language": "python",
   "name": "effective-forecasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
